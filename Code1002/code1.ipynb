{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openparse in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (0.6.0)\n",
      "Requirement already satisfied: PyMuPDF>=1.23.2 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openparse) (1.24.9)\n",
      "Requirement already satisfied: pillow>=8.3 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openparse) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openparse) (2.8.2)\n",
      "Requirement already satisfied: pypdf>=4.0.0 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openparse) (5.0.1)\n",
      "Requirement already satisfied: pdfminer.six>=20200401 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openparse) (20231228)\n",
      "Requirement already satisfied: tiktoken>=0.3 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openparse) (0.7.0)\n",
      "Requirement already satisfied: openai>=1.0.0 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openparse) (1.51.0)\n",
      "Requirement already satisfied: numpy in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openparse) (2.1.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openai>=1.0.0->openparse) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openai>=1.0.0->openparse) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openai>=1.0.0->openparse) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openai>=1.0.0->openparse) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openai>=1.0.0->openparse) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openai>=1.0.0->openparse) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openai>=1.0.0->openparse) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from pdfminer.six>=20200401->openparse) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from pdfminer.six>=20200401->openparse) (43.0.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from pydantic>=2.0->openparse) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from pydantic>=2.0->openparse) (2.20.1)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.9 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from PyMuPDF>=1.23.2->openparse) (1.24.9)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from tiktoken>=0.3->openparse) (2024.7.24)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from tiktoken>=0.3->openparse) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.0.0->openparse) (3.8)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.0.0->openparse) (1.2.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six>=20200401->openparse) (1.17.1)\n",
      "Requirement already satisfied: certifi in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->openparse) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->openparse) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->openparse) (0.14.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken>=0.3->openparse) (2.2.2)\n",
      "Requirement already satisfied: pycparser in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six>=20200401->openparse) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Docment Parser......\n",
      "Loading Surya models......\n",
      "Loaded detection model vikp/surya_layout3 on device mps with dtype torch.float16\n",
      "Loaded detection model vikp/surya_det3 on device mps with dtype torch.float16\n",
      "Loaded reading order model vikp/surya_order on device mps with dtype torch.float16\n",
      "Initializing Tesseract......\n"
     ]
    }
   ],
   "source": [
    "# Loading latest version of pdf_parser\n",
    "# auto reloads the module if it has been changed\n",
    "\n",
    "from pdf_parser import PdfParser\n",
    "\n",
    "parser = PdfParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DocumentParser' object has no attribute 'parse_pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m pdf_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m11_AuditedStatements2021_JPProcurement.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m----> 3\u001b[0m pdf_layout \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_pdf\u001b[49m(pdf_bytes)\n\u001b[1;32m      4\u001b[0m pdf_layout\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_1002_v2.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m pdf_layout\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DocumentParser' object has no attribute 'parse_pdf'"
     ]
    }
   ],
   "source": [
    "pdf_bytes = open('11_AuditedStatements2021_JPProcurement.pdf', 'rb').read()\n",
    "\n",
    "pdf_layout = parser.parse_pdf(pdf_bytes)\n",
    "pdf_layout.to_excel('output_1002_v2.xlsx', index=False)\n",
    "pdf_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_table_data_from_excel(file_path):\n",
    "    \"\"\"\n",
    "    Extract only the rows labeled as 'Table' from an Excel file and return the data in matrix format\n",
    "    containing page_idx, position, bbox, label, and text.\n",
    "    \"\"\"\n",
    "    # Load the Excel file\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # Filter for rows labeled as 'Table'\n",
    "    table_df = df[df['label'] == 'Table']\n",
    "    \n",
    "    # Select necessary columns\n",
    "    table_matrix = table_df[['page_idx', 'bbox', 'label']]\n",
    "    \n",
    "    return table_matrix\n",
    "\n",
    "# Call the function with the uploaded file path\n",
    "\n",
    "excel_file_path = 'output_1002_v2.xlsx'  # Path to the Excel file\n",
    "filtered_table_matrix = extract_table_data_from_excel(excel_file_path)\n",
    "filtered_table_matrix\n",
    "page_idx_vector = filtered_table_matrix['page_idx'].tolist()\n",
    "page_idx_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "\n",
    "# Define a function to extract and save individual pages as separate PDFs\n",
    "def extract_pages_from_pdf(input_pdf_path, output_folder, table_pages):\n",
    "    # Open the PDF document\n",
    "    doc = fitz.open(input_pdf_path)\n",
    "    \n",
    "    # List to keep track of saved PDF paths\n",
    "    saved_pdfs = []\n",
    "\n",
    "    # Loop through the provided page indices and extract the corresponding pages\n",
    "    for page_idx in table_pages:\n",
    "        # Load the page by index\n",
    "        page = doc.load_page(int(page_idx))\n",
    "\n",
    "        # Create a new PDF with just this single page\n",
    "        single_page_pdf = fitz.open()  # Initialize a new empty PDF\n",
    "        single_page_pdf.insert_pdf(doc, from_page=page_idx, to_page=page_idx)  # Insert only the single page\n",
    "\n",
    "        # Define the path for the output PDF\n",
    "        output_pdf_path = os.path.join(output_folder, f\"table_page_{page_idx + 1}.pdf\")\n",
    "        single_page_pdf.save(output_pdf_path)\n",
    "        single_page_pdf.close()\n",
    "\n",
    "        # Append the path to the list\n",
    "        saved_pdfs.append(output_pdf_path)\n",
    "\n",
    "    # Close the original PDF document\n",
    "    doc.close()\n",
    "\n",
    "    return saved_pdfs\n",
    "\n",
    "# Example usage:\n",
    "input_pdf_path = \"11_AuditedStatements2021_JPProcurement.pdf\"\n",
    "output_folder = \"extracted_table_v3\"\n",
    "table_pages = page_idx_vector\n",
    "saved_pdfs = extract_pages_from_pdf(input_pdf_path, output_folder, table_pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted PDFs saved at: ['extracted_table_v2/table_page_2.pdf', 'extracted_table_v2/table_page_3.pdf', 'extracted_table_v2/table_page_4.pdf', 'extracted_table_v2/table_page_6.pdf', 'extracted_table_v2/table_page_7.pdf', 'extracted_table_v2/table_page_8.pdf', 'extracted_table_v2/table_page_9.pdf', 'extracted_table_v2/table_page_10.pdf', 'extracted_table_v2/table_page_11.pdf', 'extracted_table_v2/table_page_12.pdf', 'extracted_table_v2/table_page_13.pdf', 'extracted_table_v2/table_page_14.pdf', 'extracted_table_v2/table_page_15.pdf']\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "\n",
    "def extract_and_save_table_pages_separately(pdf_path, table_pages, output_folder):\n",
    "    \"\"\"\n",
    "    Extract each page containing a table and save it as a separate PDF.\n",
    "\n",
    "    Parameters:\n",
    "    - pdf_path: Path to the original PDF file.\n",
    "    - table_pages: List of page indices where tables are located (ensure it's integers).\n",
    "    - output_folder: Folder to save the individual page PDFs.\n",
    "    \n",
    "    Returns:\n",
    "    - A list of paths to the saved individual PDFs.\n",
    "    \"\"\"\n",
    "    # Ensure the output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Open the original PDF\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    # List to store the paths of saved PDFs\n",
    "    saved_pdfs = []\n",
    "\n",
    "    # Loop through the provided page indices and extract the corresponding pages\n",
    "    for page_idx in table_pages:\n",
    "        page = doc.load_page(int(page_idx))  # Load the page by index\n",
    "\n",
    "        # Create a new PDF with just this single page\n",
    "        single_page_pdf = fitz.open()\n",
    "        single_page_pdf.new_page(width=page.rect.width, height=page.rect.height)\n",
    "        single_page_pdf[-1].show_pdf_page(page.rect, doc, page_idx)  # Copy the page content\n",
    "        \n",
    "        # Define the path for the output PDF\n",
    "        output_pdf_path = os.path.join(output_folder, f\"table_page_{page_idx + 1}.pdf\")\n",
    "        single_page_pdf.save(output_pdf_path)\n",
    "        single_page_pdf.close()\n",
    "\n",
    "        # Append the path to the list\n",
    "        saved_pdfs.append(output_pdf_path)\n",
    "\n",
    "    doc.close()\n",
    "\n",
    "    return saved_pdfs\n",
    "\n",
    "# Example usage:\n",
    "pdf_path = \"11_AuditedStatements2021_JPProcurement.pdf\"\n",
    "table_pages = filtered_table_matrix['page_idx'].unique().tolist()  # Convert to list of integers if necessary\n",
    "output_folder = \"extracted_table_v2\"  # Folder where individual PDFs will be saved\n",
    "\n",
    "# Extract and save each page containing tables as separate PDFs\n",
    "saved_pdfs = extract_and_save_table_pages_separately(pdf_path, table_pages, output_folder)\n",
    "\n",
    "print(f\"Extracted PDFs saved at: {saved_pdfs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed document from extracted_table_pages/table_page_2.pdf\n",
      "Parsed document from extracted_table_pages/table_page_3.pdf\n",
      "Parsed document from extracted_table_pages/table_page_4.pdf\n",
      "Parsed document from extracted_table_pages/table_page_6.pdf\n",
      "Parsed document from extracted_table_pages/table_page_7.pdf\n",
      "Parsed document from extracted_table_pages/table_page_8.pdf\n",
      "Parsed document from extracted_table_pages/table_page_9.pdf\n",
      "Parsed document from extracted_table_pages/table_page_10.pdf\n",
      "Parsed document from extracted_table_pages/table_page_11.pdf\n",
      "Parsed document from extracted_table_pages/table_page_12.pdf\n",
      "Parsed document from extracted_table_pages/table_page_13.pdf\n",
      "Parsed document from extracted_table_pages/table_page_14.pdf\n",
      "Parsed document from extracted_table_pages/table_page_15.pdf\n",
      "\n",
      "Parsed content from document 1 (extracted_table_pages/table_page_2.pdf):\n",
      "\n",
      "Parsed content from document 2 (extracted_table_pages/table_page_3.pdf):\n",
      "\n",
      "Parsed content from document 3 (extracted_table_pages/table_page_4.pdf):\n",
      "\n",
      "Parsed content from document 4 (extracted_table_pages/table_page_6.pdf):\n",
      "\n",
      "Parsed content from document 5 (extracted_table_pages/table_page_7.pdf):\n",
      "\n",
      "Parsed content from document 6 (extracted_table_pages/table_page_8.pdf):\n",
      "\n",
      "Parsed content from document 7 (extracted_table_pages/table_page_9.pdf):\n",
      "\n",
      "Parsed content from document 8 (extracted_table_pages/table_page_10.pdf):\n",
      "\n",
      "Parsed content from document 9 (extracted_table_pages/table_page_11.pdf):\n",
      "\n",
      "Parsed content from document 10 (extracted_table_pages/table_page_12.pdf):\n",
      "\n",
      "Parsed content from document 11 (extracted_table_pages/table_page_13.pdf):\n",
      "\n",
      "Parsed content from document 12 (extracted_table_pages/table_page_14.pdf):\n",
      "\n",
      "Parsed content from document 13 (extracted_table_pages/table_page_15.pdf):\n"
     ]
    }
   ],
   "source": [
    "import openparse\n",
    "\n",
    "def parse_extracted_pdfs(saved_pdfs):\n",
    "    \"\"\"\n",
    "    Parse each of the extracted single-page PDFs containing tables.\n",
    "    \n",
    "    Parameters:\n",
    "    - saved_pdfs: List of paths to the extracted single-page PDFs.\n",
    "    \n",
    "    Returns:\n",
    "    - A list of parsed documents for further processing.\n",
    "    \"\"\"\n",
    "    parser = openparse.DocumentParser()\n",
    "    parsed_docs = []\n",
    "\n",
    "    # Iterate over each saved PDF and parse it\n",
    "    for pdf_path in saved_pdfs:\n",
    "        parsed_doc = parser.parse(pdf_path)  # Parse the single-page PDF\n",
    "        parsed_docs.append(parsed_doc)\n",
    "        print(f\"Parsed document from {pdf_path}\")\n",
    "\n",
    "    return parsed_docs\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `saved_pdfs` is the output from Step 1\n",
    "parsed_docs = parse_extracted_pdfs(saved_pdfs)\n",
    "\n",
    "# Now you can analyze or print the parsed content from each document\n",
    "for i, parsed_doc in enumerate(parsed_docs):\n",
    "    print(f\"\\nParsed content from document {i + 1} ({saved_pdfs[i]}):\")\n",
    "    for node in parsed_doc.nodes:\n",
    "        print(node)  # Printing the parsed nodes for each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed document from extracted_table_pages/table_page_2.pdf with 0 nodes\n",
      "Parsed document from extracted_table_pages/table_page_8.pdf with 0 nodes\n",
      "Parsed document from extracted_table_pages/table_page_9.pdf with 0 nodes\n",
      "Parsed document from extracted_table_pages/table_page_10.pdf with 0 nodes\n",
      "Parsed document from extracted_table_pages/table_page_11.pdf with 0 nodes\n",
      "Parsed document from extracted_table_pages/table_page_13.pdf with 0 nodes\n",
      "Parsed document from extracted_table_pages/table_page_14.pdf with 0 nodes\n",
      "Parsed document from extracted_table_pages/table_page_15.pdf with 0 nodes\n",
      "Parsed document from extracted_table_pages/table_page_16.pdf with 0 nodes\n",
      "Parsed document from extracted_table_pages/table_page_17.pdf with 0 nodes\n",
      "Parsed document from extracted_table_pages/table_page_18.pdf with 0 nodes\n",
      "\n",
      "Parsed content from extracted_table_pages/table_page_2.pdf:\n",
      "\n",
      "Parsed content from extracted_table_pages/table_page_8.pdf:\n",
      "\n",
      "Parsed content from extracted_table_pages/table_page_9.pdf:\n",
      "\n",
      "Parsed content from extracted_table_pages/table_page_10.pdf:\n",
      "\n",
      "Parsed content from extracted_table_pages/table_page_11.pdf:\n",
      "\n",
      "Parsed content from extracted_table_pages/table_page_13.pdf:\n",
      "\n",
      "Parsed content from extracted_table_pages/table_page_14.pdf:\n",
      "\n",
      "Parsed content from extracted_table_pages/table_page_15.pdf:\n",
      "\n",
      "Parsed content from extracted_table_pages/table_page_16.pdf:\n",
      "\n",
      "Parsed content from extracted_table_pages/table_page_17.pdf:\n",
      "\n",
      "Parsed content from extracted_table_pages/table_page_18.pdf:\n"
     ]
    }
   ],
   "source": [
    "import openparse\n",
    "\n",
    "def parse_extracted_pdfs_and_save_nodes(saved_pdfs):\n",
    "    \"\"\"\n",
    "    Parse each of the extracted single-page PDFs containing tables and save the nodes.\n",
    "\n",
    "    Parameters:\n",
    "    - saved_pdfs: List of paths to the extracted single-page PDFs.\n",
    "    \n",
    "    Returns:\n",
    "    - A dictionary where the key is the PDF file path and the value is the list of parsed nodes for that PDF.\n",
    "    \"\"\"\n",
    "    parser = openparse.DocumentParser()\n",
    "    parsed_nodes_by_pdf = {}\n",
    "\n",
    "    # Iterate over each saved PDF and parse it\n",
    "    for pdf_path in saved_pdfs:\n",
    "        parsed_doc = parser.parse(pdf_path)  # Parse the single-page PDF\n",
    "        nodes = [node for node in parsed_doc.nodes]  # Extract nodes from the parsed document\n",
    "        \n",
    "        # Save the nodes for this particular PDF\n",
    "        parsed_nodes_by_pdf[pdf_path] = nodes\n",
    "        print(f\"Parsed document from {pdf_path} with {len(nodes)} nodes\")\n",
    "\n",
    "    return parsed_nodes_by_pdf\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `saved_pdfs` is the output from Step 1\n",
    "parsed_nodes_by_pdf = parse_extracted_pdfs_and_save_nodes(saved_pdfs)\n",
    "\n",
    "# Now you can access and analyze the nodes from each PDF\n",
    "for pdf_path, nodes in parsed_nodes_by_pdf.items():\n",
    "    print(f\"\\nParsed content from {pdf_path}:\")\n",
    "    for node in nodes:\n",
    "        print(node)  # Printing each node for this specific PDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pdfs_and_save_nodes_to_df(saved_pdfs):\n",
    "    \"\"\"\n",
    "    Parse each of the extracted single-page PDFs containing tables and save their nodes in a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - saved_pdfs: List of paths to the extracted single-page PDFs.\n",
    "    \n",
    "    Returns:\n",
    "    - A DataFrame containing the parsed nodes with their document index and content.\n",
    "    \"\"\"\n",
    "    parser = openparse.DocumentParser()\n",
    "    parsed_data = []\n",
    "\n",
    "    # Iterate over each saved PDF and parse it\n",
    "    for i, pdf_path in enumerate(saved_pdfs):\n",
    "        parsed_doc = parser.parse(pdf_path)  # Parse the single-page PDF\n",
    "        print(f\"Parsed document from {pdf_path}\")\n",
    "        \n",
    "        # Iterate over the nodes in the parsed document\n",
    "        for node in parsed_doc.nodes:\n",
    "            # Save the document index and node content in the parsed data list\n",
    "            parsed_data.append({\n",
    "                'document_index': i + 1,  # Document number (1-based index)\n",
    "                #'pdf_path': pdf_path,\n",
    "                'node_content': str(node)\n",
    "            })\n",
    "\n",
    "    # Convert the parsed data into a DataFrame\n",
    "    parsed_df = pd.DataFrame(parsed_data)\n",
    "    \n",
    "    return parsed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed document from extracted_table_v2/table_page_2.pdf\n",
      "Parsed document from extracted_table_v2/table_page_3.pdf\n",
      "Parsed document from extracted_table_v2/table_page_4.pdf\n",
      "Parsed document from extracted_table_v2/table_page_6.pdf\n",
      "Parsed document from extracted_table_v2/table_page_7.pdf\n",
      "Parsed document from extracted_table_v2/table_page_8.pdf\n",
      "Parsed document from extracted_table_v2/table_page_9.pdf\n",
      "Parsed document from extracted_table_v2/table_page_10.pdf\n",
      "Parsed document from extracted_table_v2/table_page_11.pdf\n",
      "Parsed document from extracted_table_v2/table_page_12.pdf\n",
      "Parsed document from extracted_table_v2/table_page_13.pdf\n",
      "Parsed document from extracted_table_v2/table_page_14.pdf\n",
      "Parsed document from extracted_table_v2/table_page_15.pdf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parsed_nodes_df = parse_pdfs_and_save_nodes_to_df(saved_pdfs)\n",
    "parsed_nodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted_table_v2/table_page_2.pdf\n",
      "extracted_table_v2/table_page_3.pdf\n",
      "extracted_table_v2/table_page_4.pdf\n",
      "extracted_table_v2/table_page_6.pdf\n",
      "extracted_table_v2/table_page_7.pdf\n",
      "extracted_table_v2/table_page_8.pdf\n",
      "extracted_table_v2/table_page_9.pdf\n",
      "extracted_table_v2/table_page_10.pdf\n",
      "extracted_table_v2/table_page_11.pdf\n",
      "extracted_table_v2/table_page_12.pdf\n",
      "extracted_table_v2/table_page_13.pdf\n",
      "extracted_table_v2/table_page_14.pdf\n",
      "extracted_table_v2/table_page_15.pdf\n",
      "[Empty DataFrame\n",
      "Columns: []\n",
      "Index: [], Empty DataFrame\n",
      "Columns: []\n",
      "Index: [], Empty DataFrame\n",
      "Columns: []\n",
      "Index: [], Empty DataFrame\n",
      "Columns: []\n",
      "Index: [], Empty DataFrame\n",
      "Columns: []\n",
      "Index: [], Empty DataFrame\n",
      "Columns: []\n",
      "Index: [], Empty DataFrame\n",
      "Columns: []\n",
      "Index: [], Empty DataFrame\n",
      "Columns: []\n",
      "Index: [], Empty DataFrame\n",
      "Columns: []\n",
      "Index: [], Empty DataFrame\n",
      "Columns: []\n",
      "Index: [], Empty DataFrame\n",
      "Columns: []\n",
      "Index: [], Empty DataFrame\n",
      "Columns: []\n",
      "Index: [], Empty DataFrame\n",
      "Columns: []\n",
      "Index: []]\n"
     ]
    }
   ],
   "source": [
    "import openparse\n",
    "import pandas as pd\n",
    "\n",
    "def parse_pdfs_and_save_nodes_per_page(saved_pdfs):\n",
    "    \"\"\"\n",
    "    Parse each of the extracted single-page PDFs containing tables and save their nodes in a separate DataFrame per page.\n",
    "    \n",
    "    Parameters:\n",
    "    - saved_pdfs: List of paths to the extracted single-page PDFs.\n",
    "    \n",
    "    Returns:\n",
    "    - A list of DataFrames, each containing the parsed nodes for a specific PDF page.\n",
    "    \"\"\"\n",
    "    parser = openparse.DocumentParser()\n",
    "    parsed_dataframes = []  # To store the DataFrame for each page\n",
    "    \n",
    "    # Iterate over each saved PDF and parse it\n",
    "    for i, pdf_path in enumerate(saved_pdfs):\n",
    "        print(pdf_path)\n",
    "        parsed_doc = parser.parse(pdf_path) \n",
    "        #print(f\"Parsed document from {pdf_path}\")\n",
    "        \n",
    "        # Collect node content for each page into a list of dictionaries\n",
    "        parsed_data = []\n",
    "        for node in parsed_doc.nodes:\n",
    "            print(node)\n",
    "            #parsed_data.append({\n",
    "            #    'document_index': i + 1,  # Document number (1-based index)\n",
    "            #    'pdf_path': pdf_path,\n",
    "            #    'node_content': str(node)\n",
    "            #})\n",
    "        \n",
    "        # Convert the parsed data into a temporary DataFrame for this PDF page\n",
    "        temp_df = pd.DataFrame(parsed_data)\n",
    "        parsed_dataframes.append(temp_df)\n",
    "        \n",
    "        # Display the temporary DataFrame for the current PDF page\n",
    "        #print(f\"Temporary DataFrame for document {i + 1} ({pdf_path}):\")\n",
    "    print(parsed_dataframes)\n",
    "    return parsed_dataframes  # Return a list of DataFrames for each page\n",
    "\n",
    "# Parse and save the nodes in separate DataFrames per page\n",
    "parsed_dataframes = parse_pdfs_and_save_nodes_per_page(saved_pdfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openparse\n",
    "basic_doc_path = \"extracted_table_v2/table_page_15.pdf\"\n",
    "parser = openparse.DocumentParser()\n",
    "parsed_basic_doc=parser.parse(basic_doc_path)\n",
    "\n",
    "for node in parsed_basic_doc.nodes:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openparse\n",
    "\n",
    "def parse_extracted_pdfs_and_calculate_bbox(saved_pdfs, exclude_texts=None):\n",
    "    \"\"\"\n",
    "    Parse each of the extracted single-page PDFs containing tables, save the nodes, and calculate the bounding box.\n",
    "\n",
    "    Parameters:\n",
    "    - saved_pdfs: List of paths to the extracted single-page PDFs.\n",
    "    - exclude_texts: List of texts to exclude when calculating the bounding box (optional).\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary where the key is the PDF file path and the value is a tuple:\n",
    "      (list of parsed nodes, calculated bounding box).\n",
    "    \"\"\"\n",
    "    parser = openparse.DocumentParser()\n",
    "    parsed_nodes_and_bbox_by_pdf = {}\n",
    "\n",
    "    # Iterate over each saved PDF and parse it\n",
    "    for pdf_path in saved_pdfs:\n",
    "        parsed_doc = parser.parse(pdf_path)  # Parse the single-page PDF\n",
    "        nodes = [node for node in parsed_doc.nodes]  # Extract nodes from the parsed document\n",
    "\n",
    "        # Calculate the bounding box using the nodes for the current page\n",
    "        max_bbox = calculate_maximum_bounding_box(nodes, exclude_texts)  # Use the function you provided\n",
    "        \n",
    "        # Save both the nodes and the calculated bounding box for this particular PDF\n",
    "        parsed_nodes_and_bbox_by_pdf[pdf_path] = (nodes, max_bbox)\n",
    "        print(f\"Parsed document from {pdf_path} with {len(nodes)} nodes and calculated bounding box\")\n",
    "\n",
    "    return parsed_nodes_and_bbox_by_pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mparse_extracted_pdfs_and_calculate_bbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43msaved_pdfs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[32], line 24\u001b[0m, in \u001b[0;36mparse_extracted_pdfs_and_calculate_bbox\u001b[0;34m(saved_pdfs, exclude_texts)\u001b[0m\n\u001b[1;32m     21\u001b[0m nodes \u001b[38;5;241m=\u001b[39m [node \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m parsed_doc\u001b[38;5;241m.\u001b[39mnodes]  \u001b[38;5;66;03m# Extract nodes from the parsed document\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Calculate the bounding box using the nodes for the current page\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m max_bbox \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_maximum_bounding_box\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_texts\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Use the function you provided\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Save both the nodes and the calculated bounding box for this particular PDF\u001b[39;00m\n\u001b[1;32m     27\u001b[0m parsed_nodes_and_bbox_by_pdf[pdf_path] \u001b[38;5;241m=\u001b[39m (nodes, max_bbox)\n",
      "Cell \u001b[0;32mIn[38], line 58\u001b[0m, in \u001b[0;36mcalculate_maximum_bounding_box\u001b[0;34m(nodes, exclude_texts)\u001b[0m\n\u001b[1;32m     56\u001b[0m x0_min_bounded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, x0_min)  \u001b[38;5;66;03m# x0_min should not be less than 0\u001b[39;00m\n\u001b[1;32m     57\u001b[0m y0_min_bounded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, y0_min)  \u001b[38;5;66;03m# y0_min should not be less than 0\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m x1_max_bounded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpage_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1_max\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# x1_max should not exceed page_width\u001b[39;00m\n\u001b[1;32m     59\u001b[0m y1_max_bounded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(page_height, y1_max)  \u001b[38;5;66;03m# y1_max should not exceed page_height\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Optionally, adjust the bounding box by a margin (e.g., 100 units)\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "parse_extracted_pdfs_and_calculate_bbox(saved_pdfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_maximum_bounding_box(nodes, exclude_texts=None):\n",
    "    \"\"\"\n",
    "    Calculate the maximum bounding box from a list of parsed nodes for a specific page.\n",
    "    \n",
    "    Parameters:\n",
    "    - nodes: List of parsed nodes for a specific page.\n",
    "    - exclude_texts: List of texts to exclude when calculating the bounding box.\n",
    "    \n",
    "    Returns:\n",
    "    - A dictionary containing the label and max_bbox.\n",
    "    \"\"\"\n",
    "    # Initialize variables to store the minimum x0, y0 and maximum x1, y1\n",
    "    x0_min = float('inf')\n",
    "    y0_min = float('inf')\n",
    "    x1_max = float('-inf')\n",
    "    y1_max = float('-inf')\n",
    "\n",
    "    # Initialize variables for page width and height (assuming all pages have the same dimensions)\n",
    "    page_width = None\n",
    "    page_height = None\n",
    "    \n",
    "    # Initialize an empty list to store the bbox coordinates\n",
    "    bbox_data = []\n",
    "\n",
    "    # Iterate through all the nodes in the parsed document\n",
    "    for node in nodes:\n",
    "        # Check if the node has a bbox attribute\n",
    "        if hasattr(node, 'bbox'):\n",
    "            # Check if the node contains any of the excluded text\n",
    "            if exclude_texts and any(exclude_text in node.text for exclude_text in exclude_texts):\n",
    "                continue  # Skip this node if it contains the excluded text\n",
    "\n",
    "            bbox_list = node.bbox  # Assuming bbox is a list of Bbox objects\n",
    "\n",
    "            # Iterate over bbox_list (in case there are multiple Bbox objects)\n",
    "            for bbox in bbox_list:\n",
    "                # Extract page dimensions if not already set\n",
    "                if page_width is None or page_height is None:\n",
    "                    page_width = bbox.page_width\n",
    "                    page_height = bbox.page_height\n",
    "\n",
    "                # Extract x0, y0, x1, y1 from the Bbox object\n",
    "                x0, y0, x1, y1 = bbox.x0, bbox.y0, bbox.x1, bbox.y1\n",
    "\n",
    "                # Append the values to bbox_data list\n",
    "                bbox_data.append([x0, y0, x1, y1])\n",
    "\n",
    "                # Update the min and max values for x0, y0, x1, y1\n",
    "                x0_min = min(x0_min, x0)\n",
    "                y0_min = min(y0_min, y0)\n",
    "                x1_max = max(x1_max, x1)\n",
    "                y1_max = max(y1_max, y1)\n",
    "\n",
    "    # Ensure the min and max bounding box values are bounded by the page dimensions\n",
    "    x0_min_bounded = max(0, x0_min)  # x0_min should not be less than 0\n",
    "    y0_min_bounded = max(0, y0_min)  # y0_min should not be less than 0\n",
    "    x1_max_bounded = min(page_width, x1_max)  # x1_max should not exceed page_width\n",
    "    y1_max_bounded = min(page_height, y1_max)  # y1_max should not exceed page_height\n",
    "\n",
    "    # Optionally, adjust the bounding box by a margin (e.g., 100 units)\n",
    "    x0_min_adjusted = max(0, x0_min_bounded)\n",
    "    y0_min_adjusted = max(0, y0_min_bounded)\n",
    "    x1_max_adjusted = min(page_width, x1_max_bounded)\n",
    "    y1_max_adjusted = min(page_height, y1_max_bounded)\n",
    "\n",
    "    # Create the max bounding box as a list\n",
    "    max_bbox = [x0_min_adjusted, y0_min_adjusted, x1_max_adjusted, y1_max_adjusted]\n",
    "\n",
    "    # Create the object with the label \"table\" and the max_bbox\n",
    "    objects = [{'label': 'table', 'bbox': max_bbox}]\n",
    "\n",
    "    # Return the objects list\n",
    "    print(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Page dimensions could not be extracted from bbox.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 84\u001b[0m\n\u001b[1;32m     82\u001b[0m exclude_texts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatement of Financial Position\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe financial statements and accounting policies on pages 6\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     83\u001b[0m parsed_nodes_for_page \u001b[38;5;241m=\u001b[39m parsed_nodes_by_pdf[saved_pdfs[\u001b[38;5;241m0\u001b[39m]]  \u001b[38;5;66;03m# Example parsed nodes for a specific page\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m calculated_bbox \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_maximum_bounding_box\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_nodes_for_page\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Output the calculated bounding box\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(calculated_bbox)\n",
      "Cell \u001b[0;32mIn[40], line 65\u001b[0m, in \u001b[0;36mcalculate_maximum_bounding_box\u001b[0;34m(nodes, exclude_texts)\u001b[0m\n\u001b[1;32m     63\u001b[0m     y1_max_bounded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(page_height, y1_max)  \u001b[38;5;66;03m# y1_max should not exceed page_height\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPage dimensions could not be extracted from bbox.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Optionally, adjust the bounding box by a margin (you can customize this)\u001b[39;00m\n\u001b[1;32m     68\u001b[0m x0_min_adjusted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, x0_min_bounded)\n",
      "\u001b[0;31mValueError\u001b[0m: Page dimensions could not be extracted from bbox."
     ]
    }
   ],
   "source": [
    "def calculate_maximum_bounding_box(nodes, exclude_texts=None):\n",
    "    \"\"\"\n",
    "    Calculate the maximum bounding box from a list of parsed nodes for a specific page.\n",
    "    \n",
    "    Parameters:\n",
    "    - nodes: List of parsed nodes for a specific page.\n",
    "    - exclude_texts: List of texts to exclude when calculating the bounding box.\n",
    "    \n",
    "    Returns:\n",
    "    - A dictionary containing the label and max_bbox.\n",
    "    \"\"\"\n",
    "    # Initialize variables to store the minimum x0, y0 and maximum x1, y1\n",
    "    x0_min = float('inf')\n",
    "    y0_min = float('inf')\n",
    "    x1_max = float('-inf')\n",
    "    y1_max = float('-inf')\n",
    "\n",
    "    # Initialize variables for page width and height\n",
    "    page_width = None\n",
    "    page_height = None\n",
    "\n",
    "    # Initialize an empty list to store the bbox coordinates\n",
    "    bbox_data = []\n",
    "\n",
    "    # Iterate through all the nodes in the parsed document\n",
    "    for node in nodes:\n",
    "        # Check if the node has a bbox attribute\n",
    "        if hasattr(node, 'bbox'):\n",
    "            # Check if the node contains any of the excluded text\n",
    "            if exclude_texts and any(exclude_text in node.text for exclude_text in exclude_texts):\n",
    "                continue  # Skip this node if it contains the excluded text\n",
    "\n",
    "            bbox_list = node.bbox  # Assuming bbox is a list of Bbox objects or a single Bbox object\n",
    "\n",
    "            # Handle both cases: whether `bbox_list` is a list or a single bbox object\n",
    "            if not isinstance(bbox_list, list):\n",
    "                bbox_list = [bbox_list]\n",
    "\n",
    "            # Iterate over bbox_list (to handle multiple bbox objects)\n",
    "            for bbox in bbox_list:\n",
    "                # Extract page dimensions (only once, if not already set)\n",
    "                if page_width is None or page_height is None:\n",
    "                    page_width = bbox.page_width\n",
    "                    page_height = bbox.page_height\n",
    "\n",
    "                # Extract x0, y0, x1, y1 from the Bbox object\n",
    "                x0, y0, x1, y1 = bbox.x0, bbox.y0, bbox.x1, bbox.y1\n",
    "\n",
    "                # Append the values to bbox_data list\n",
    "                bbox_data.append([x0, y0, x1, y1])\n",
    "\n",
    "                # Update the min and max values for x0, y0, x1, y1\n",
    "                x0_min = min(x0_min, x0)\n",
    "                y0_min = min(y0_min, y0)\n",
    "                x1_max = max(x1_max, x1)\n",
    "                y1_max = max(y1_max, y1)\n",
    "\n",
    "    # Ensure the min and max bounding box values are bounded by the page dimensions\n",
    "    if page_width is not None and page_height is not None:\n",
    "        x0_min_bounded = max(0, x0_min)  # x0_min should not be less than 0\n",
    "        y0_min_bounded = max(0, y0_min)  # y0_min should not be less than 0\n",
    "        x1_max_bounded = min(page_width, x1_max)  # x1_max should not exceed page_width\n",
    "        y1_max_bounded = min(page_height, y1_max)  # y1_max should not exceed page_height\n",
    "    else:\n",
    "        raise ValueError(\"Page dimensions could not be extracted from bbox.\")\n",
    "\n",
    "    # Optionally, adjust the bounding box by a margin (you can customize this)\n",
    "    x0_min_adjusted = max(0, x0_min_bounded)\n",
    "    y0_min_adjusted = max(0, y0_min_bounded)\n",
    "    x1_max_adjusted = min(page_width, x1_max_bounded)\n",
    "    y1_max_adjusted = min(page_height, y1_max_bounded)\n",
    "\n",
    "    # Create the max bounding box as a list\n",
    "    max_bbox = [x0_min_adjusted, y0_min_adjusted, x1_max_adjusted, y1_max_adjusted]\n",
    "\n",
    "    # Create the object with the label \"table\" and the max_bbox\n",
    "    objects = [{'label': 'table', 'bbox': max_bbox}]\n",
    "\n",
    "    return objects\n",
    "\n",
    "# Example usage of the function\n",
    "exclude_texts = ['Statement of Financial Position', 'The financial statements and accounting policies on pages 6']\n",
    "parsed_nodes_for_page = parsed_nodes_by_pdf[saved_pdfs[0]]  # Example parsed nodes for a specific page\n",
    "calculated_bbox = calculate_maximum_bounding_box(parsed_nodes_for_page, exclude_texts)\n",
    "\n",
    "# Output the calculated bounding box\n",
    "print(calculated_bbox)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parsed_nodes_by_pdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 89\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Example usage of the function\u001b[39;00m\n\u001b[1;32m     88\u001b[0m exclude_texts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatement of Financial Position\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe financial statements and accounting policies on pages 6\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 89\u001b[0m parsed_nodes_for_page \u001b[38;5;241m=\u001b[39m \u001b[43mparsed_nodes_by_pdf\u001b[49m[saved_pdfs[\u001b[38;5;241m0\u001b[39m]]  \u001b[38;5;66;03m# Example parsed nodes for a specific page\u001b[39;00m\n\u001b[1;32m     90\u001b[0m calculated_bbox \u001b[38;5;241m=\u001b[39m calculate_maximum_bounding_box(parsed_nodes_for_page, exclude_texts)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Output the calculated bounding box\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parsed_nodes_by_pdf' is not defined"
     ]
    }
   ],
   "source": [
    "def calculate_maximum_bounding_box(nodes, exclude_texts=None):\n",
    "    \"\"\"\n",
    "    Calculate the maximum bounding box from a list of parsed nodes for a specific page.\n",
    "    \n",
    "    Parameters:\n",
    "    - nodes: List of parsed nodes for a specific page.\n",
    "    - exclude_texts: List of texts to exclude when calculating the bounding box.\n",
    "    \n",
    "    Returns:\n",
    "    - A dictionary containing the label and max_bbox.\n",
    "    \"\"\"\n",
    "    # Initialize variables to store the minimum x0, y0 and maximum x1, y1\n",
    "    x0_min = float('inf')\n",
    "    y0_min = float('inf')\n",
    "    x1_max = float('-inf')\n",
    "    y1_max = float('-inf')\n",
    "\n",
    "    # Initialize variables for page width and height\n",
    "    page_width = None\n",
    "    page_height = None\n",
    "\n",
    "    # Initialize an empty list to store the bbox coordinates\n",
    "    bbox_data = []\n",
    "\n",
    "    # Iterate through all the nodes in the parsed document\n",
    "    for node in nodes:\n",
    "        # Check if the node has a bbox attribute\n",
    "        if hasattr(node, 'bbox'):\n",
    "            # Check if the node contains any of the excluded text\n",
    "            if exclude_texts and any(exclude_text in node.text for exclude_text in exclude_texts):\n",
    "                continue  # Skip this node if it contains the excluded text\n",
    "\n",
    "            bbox_list = node.bbox  # Assuming bbox is a list of Bbox objects or a single Bbox object\n",
    "\n",
    "            # Handle both cases: whether `bbox_list` is a list or a single bbox object\n",
    "            if not isinstance(bbox_list, list):\n",
    "                bbox_list = [bbox_list]\n",
    "\n",
    "            # Iterate over bbox_list (to handle multiple bbox objects)\n",
    "            for bbox in bbox_list:\n",
    "                # Extract page dimensions (only once, if not already set)\n",
    "                if page_width is None or page_height is None:\n",
    "                    if hasattr(bbox, 'page_width') and hasattr(bbox, 'page_height'):\n",
    "                        page_width = bbox.page_width\n",
    "                        page_height = bbox.page_height\n",
    "                    else:\n",
    "                        # Skip this node if page dimensions are missing\n",
    "                        print(f\"Skipping bbox on page {bbox.page} due to missing page dimensions.\")\n",
    "                        continue\n",
    "\n",
    "                # Extract x0, y0, x1, y1 from the Bbox object\n",
    "                x0, y0, x1, y1 = bbox.x0, bbox.y0, bbox.x1, bbox.y1\n",
    "\n",
    "                # Append the values to bbox_data list\n",
    "                bbox_data.append([x0, y0, x1, y1])\n",
    "\n",
    "                # Update the min and max values for x0, y0, x1, y1\n",
    "                x0_min = min(x0_min, x0)\n",
    "                y0_min = min(y0_min, y0)\n",
    "                x1_max = max(x1_max, x1)\n",
    "                y1_max = max(y1_max, y1)\n",
    "\n",
    "    # Ensure the min and max bounding box values are bounded by the page dimensions\n",
    "    if page_width is not None and page_height is not None:\n",
    "        x0_min_bounded = max(0, x0_min)  # x0_min should not be less than 0\n",
    "        y0_min_bounded = max(0, y0_min)  # y0_min should not be less than 0\n",
    "        x1_max_bounded = min(page_width, x1_max)  # x1_max should not exceed page_width\n",
    "        y1_max_bounded = min(page_height, y1_max)  # y1_max should not exceed page_height\n",
    "    else:\n",
    "        print(\"Warning: Page dimensions not found for any nodes. Returning empty bounding box.\")\n",
    "        return []\n",
    "\n",
    "    # Optionally, adjust the bounding box by a margin (you can customize this)\n",
    "    x0_min_adjusted = max(0, x0_min_bounded)\n",
    "    y0_min_adjusted = max(0, y0_min_bounded)\n",
    "    x1_max_adjusted = min(page_width, x1_max_bounded)\n",
    "    y1_max_adjusted = min(page_height, y1_max_bounded)\n",
    "\n",
    "    # Create the max bounding box as a list\n",
    "    max_bbox = [x0_min_adjusted, y0_min_adjusted, x1_max_adjusted, y1_max_adjusted]\n",
    "\n",
    "    # Create the object with the label \"table\" and the max_bbox\n",
    "    objects = [{'label': 'table', 'bbox': max_bbox}]\n",
    "\n",
    "    return objects\n",
    "\n",
    "# Example usage of the function\n",
    "exclude_texts = ['Statement of Financial Position', 'The financial statements and accounting policies on pages 6']\n",
    "parsed_nodes_for_page = parsed_nodes_by_pdf[saved_pdfs[0]]  # Example parsed nodes for a specific page\n",
    "calculated_bbox = calculate_maximum_bounding_box(parsed_nodes_for_page, exclude_texts)\n",
    "\n",
    "# Output the calculated bounding box\n",
    "print(calculated_bbox)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parse_extracted_pdfs_and_calculate_bbox' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Assuming `saved_pdfs` is the output from Step 1\u001b[39;00m\n\u001b[1;32m      3\u001b[0m exclude_texts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatement of Financial Position\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe financial statements and accounting policies on pages 6\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m parsed_nodes_and_bbox_by_pdf \u001b[38;5;241m=\u001b[39m \u001b[43mparse_extracted_pdfs_and_calculate_bbox\u001b[49m(saved_pdfs, exclude_texts)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Now you can access the parsed nodes and calculated bounding box from each PDF\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pdf_path, (nodes, bbox) \u001b[38;5;129;01min\u001b[39;00m parsed_nodes_and_bbox_by_pdf\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parse_extracted_pdfs_and_calculate_bbox' is not defined"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "# Assuming `saved_pdfs` is the output from Step 1\n",
    "exclude_texts = ['Statement of Financial Position', 'The financial statements and accounting policies on pages 6']\n",
    "parsed_nodes_and_bbox_by_pdf = parse_extracted_pdfs_and_calculate_bbox(saved_pdfs, exclude_texts)\n",
    "\n",
    "# Now you can access the parsed nodes and calculated bounding box from each PDF\n",
    "for pdf_path, (nodes, bbox) in parsed_nodes_and_bbox_by_pdf.items():\n",
    "    print(f\"\\nParsed content and bounding box from {pdf_path}:\")\n",
    "    print(f\"Nodes: {nodes}\")\n",
    "    print(f\"Bounding Box: {bbox}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surya",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
