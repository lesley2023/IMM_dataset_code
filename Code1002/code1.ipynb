{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openparse in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (0.6.0)\n",
      "Requirement already satisfied: PyMuPDF>=1.23.2 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openparse) (1.24.9)\n",
      "Requirement already satisfied: pillow>=8.3 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openparse) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openparse) (2.8.2)\n",
      "Requirement already satisfied: pypdf>=4.0.0 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openparse) (5.0.1)\n",
      "Requirement already satisfied: pdfminer.six>=20200401 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openparse) (20231228)\n",
      "Requirement already satisfied: tiktoken>=0.3 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openparse) (0.7.0)\n",
      "Requirement already satisfied: openai>=1.0.0 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openparse) (1.51.0)\n",
      "Requirement already satisfied: numpy in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openparse) (2.1.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openai>=1.0.0->openparse) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openai>=1.0.0->openparse) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openai>=1.0.0->openparse) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openai>=1.0.0->openparse) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openai>=1.0.0->openparse) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openai>=1.0.0->openparse) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from openai>=1.0.0->openparse) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from pdfminer.six>=20200401->openparse) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from pdfminer.six>=20200401->openparse) (43.0.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from pydantic>=2.0->openparse) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from pydantic>=2.0->openparse) (2.20.1)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.9 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from PyMuPDF>=1.23.2->openparse) (1.24.9)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from tiktoken>=0.3->openparse) (2024.7.24)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from tiktoken>=0.3->openparse) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.0.0->openparse) (3.8)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.0.0->openparse) (1.2.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six>=20200401->openparse) (1.17.1)\n",
      "Requirement already satisfied: certifi in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->openparse) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->openparse) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->openparse) (0.14.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken>=0.3->openparse) (2.2.2)\n",
      "Requirement already satisfied: pycparser in /Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six>=20200401->openparse) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lesleywang/anaconda3/envs/surya/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Docment Parser......\n",
      "Loading Surya models......\n",
      "Loaded detection model vikp/surya_layout3 on device mps with dtype torch.float16\n",
      "Loaded detection model vikp/surya_det3 on device mps with dtype torch.float16\n",
      "Loaded reading order model vikp/surya_order on device mps with dtype torch.float16\n",
      "Initializing Tesseract......\n"
     ]
    }
   ],
   "source": [
    "# Loading latest version of pdf_parser\n",
    "# auto reloads the module if it has been changed\n",
    "\n",
    "from pdf_parser import PdfParser\n",
    "\n",
    "parser = PdfParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pdf = 'pic2.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  2.56it/s]\n",
      "Finding reading order: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "pdf_bytes = open('pic2.pdf', 'rb').read()\n",
    "\n",
    "pdf_layout = parser.parse_pdf(pdf_bytes)\n",
    "pdf_layout.to_excel('output_pic2.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_idx</th>\n",
       "      <th>position</th>\n",
       "      <th>bbox</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(162, 150, 567, 218)</td>\n",
       "      <td>Section-header</td>\n",
       "      <td>Mountain Beverages Limited\\nBusiness Report an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(162, 244, 466, 267)</td>\n",
       "      <td>Section-header</td>\n",
       "      <td>Statement of Financial Position\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(152, 252, 1076, 1289)</td>\n",
       "      <td>Table</td>\n",
       "      <td>SLALOMeHt OF PInahtial PUSIIOH\\n\\nASSETS Notes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(161, 1297, 1051, 1344)</td>\n",
       "      <td>Text</td>\n",
       "      <td>The financial statements and accounting polici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>(369, 1406, 456, 1429)</td>\n",
       "      <td>Text</td>\n",
       "      <td>Director\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>(584, 1556, 605, 1579)</td>\n",
       "      <td>Text</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_idx  position                     bbox           label  \\\n",
       "0         0         0     (162, 150, 567, 218)  Section-header   \n",
       "1         0         1     (162, 244, 466, 267)  Section-header   \n",
       "2         0         2   (152, 252, 1076, 1289)           Table   \n",
       "3         0         3  (161, 1297, 1051, 1344)            Text   \n",
       "4         0         4   (369, 1406, 456, 1429)            Text   \n",
       "5         0         5   (584, 1556, 605, 1579)            Text   \n",
       "\n",
       "                                                text  \n",
       "0  Mountain Beverages Limited\\nBusiness Report an...  \n",
       "1                  Statement of Financial Position\\n  \n",
       "2  SLALOMeHt OF PInahtial PUSIIOH\\n\\nASSETS Notes...  \n",
       "3  The financial statements and accounting polici...  \n",
       "4                                         Director\\n  \n",
       "5                                                     "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_idx</th>\n",
       "      <th>bbox</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>(152, 252, 1076, 1289)</td>\n",
       "      <td>Table</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_idx                    bbox  label\n",
       "2         0  (152, 252, 1076, 1289)  Table"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_table_data_from_excel(file_path):\n",
    "    \"\"\"\n",
    "    Extract only the rows labeled as 'Table' from an Excel file and return the data in matrix format\n",
    "    containing page_idx, position, bbox, label, and text.\n",
    "    \"\"\"\n",
    "    # Load the Excel file\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # Filter for rows labeled as 'Table'\n",
    "    table_df = df[df['label'] == 'Table']\n",
    "    \n",
    "    # Select necessary columns\n",
    "    table_matrix = table_df[['page_idx', 'bbox', 'label']]\n",
    "    \n",
    "    return table_matrix\n",
    "\n",
    "# Call the function with the uploaded file path\n",
    "\n",
    "excel_file_path = 'output_pic2.xlsx'  # Path to the Excel file\n",
    "filtered_table_matrix = extract_table_data_from_excel(excel_file_path)\n",
    "filtered_table_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'nodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 112\u001b[0m\n\u001b[1;32m    109\u001b[0m exclude_texts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatement of Financial Position\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe financial statements and accounting policies on pages 6\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    110\u001b[0m output_png_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpage_cropped\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 112\u001b[0m \u001b[43mcrop_and_save_table_pages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiltered_table_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_png_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_texts\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 67\u001b[0m, in \u001b[0;36mcrop_and_save_table_pages\u001b[0;34m(pdf_path, table_matrix, parsed_basic_doc, output_png_prefix, exclude_texts)\u001b[0m\n\u001b[1;32m     64\u001b[0m table_pages \u001b[38;5;241m=\u001b[39m table_matrix[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Get the maximum bounding box for each table-containing page\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m max_bboxes \u001b[38;5;241m=\u001b[39m \u001b[43mget_maximum_bounding_box\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_basic_doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_pages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Open the PDF with PyMuPDF (fitz)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m doc \u001b[38;5;241m=\u001b[39m fitz\u001b[38;5;241m.\u001b[39mopen(pdf_path)\n",
      "Cell \u001b[0;32mIn[21], line 20\u001b[0m, in \u001b[0;36mget_maximum_bounding_box\u001b[0;34m(parsed_basic_doc, table_pages, exclude_texts)\u001b[0m\n\u001b[1;32m     17\u001b[0m page_bboxes \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Iterate through all the nodes in the parsed document\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[43mparsed_basic_doc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m:\n\u001b[1;32m     21\u001b[0m     page_idx \u001b[38;5;241m=\u001b[39m node[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Only process nodes from pages containing tables\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'nodes'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def get_maximum_bounding_box(parsed_basic_doc, table_pages, exclude_texts):\n",
    "    \"\"\"\n",
    "    Get the maximum bounding box across all the bounding boxes for each table page.\n",
    "\n",
    "    Parameters:\n",
    "    - parsed_basic_doc: The parsed document object.\n",
    "    - table_pages: A list of page indices where tables are located.\n",
    "    - exclude_texts: A list of text snippets to exclude when calculating the bounding box.\n",
    "    \n",
    "    Returns:\n",
    "    - A dictionary with page indices as keys and max bounding boxes as values.\n",
    "    \"\"\"\n",
    "    # Dictionary to store the maximum bounding box for each page\n",
    "    page_bboxes = {}\n",
    "\n",
    "    # Iterate through all the nodes in the parsed document\n",
    "    for node in parsed_basic_doc.nodes:\n",
    "        page_idx = node['page_idx']\n",
    "\n",
    "        # Only process nodes from pages containing tables\n",
    "        if page_idx in table_pages:\n",
    "            # Skip nodes that contain excluded texts\n",
    "            if any(exclude_text in node.text for exclude_text in exclude_texts):\n",
    "                continue\n",
    "\n",
    "            # Initialize variables to store the minimum x0, y0 and maximum x1, y1\n",
    "            x0_min, y0_min = float('inf'), float('inf')\n",
    "            x1_max, y1_max = float('-inf'), float('-inf')\n",
    "\n",
    "            # Check if the node has a bbox attribute\n",
    "            if hasattr(node, 'bbox'):\n",
    "                bbox_list = node.bbox  # Assuming bbox is a list of Bbox objects\n",
    "\n",
    "                # Iterate over bbox_list (in case there are multiple Bbox objects)\n",
    "                for bbox in bbox_list:\n",
    "                    x0, y0, x1, y1 = bbox.x0, bbox.y0, bbox.x1, bbox.y1\n",
    "\n",
    "                    # Update the min and max values for x0, y0, x1, y1\n",
    "                    x0_min = min(x0_min, x0)\n",
    "                    y0_min = min(y0_min, y0)\n",
    "                    x1_max = max(x1_max, x1)\n",
    "                    y1_max = max(y1_max, y1)\n",
    "\n",
    "                # Store the bounding box for the current page\n",
    "                page_bboxes[page_idx] = [x0_min, y0_min, x1_max, y1_max]\n",
    "\n",
    "    return page_bboxes\n",
    "\n",
    "def crop_and_save_table_pages(pdf_path, table_matrix, parsed_basic_doc, output_png_prefix, exclude_texts):\n",
    "    \"\"\"\n",
    "    Crop the pages that contain tables based on their bounding box and save them as PNGs.\n",
    "\n",
    "    Parameters:\n",
    "    - pdf_path: Path to the original PDF file.\n",
    "    - table_matrix: A DataFrame containing page_idx of table locations.\n",
    "    - parsed_basic_doc: The parsed document object.\n",
    "    - output_png_prefix: Prefix for naming the output PNG files.\n",
    "    - exclude_texts: A list of text snippets to exclude when calculating the bounding box.\n",
    "    \"\"\"\n",
    "    # Get the unique page numbers where tables are located\n",
    "    table_pages = table_matrix['page_idx'].unique()\n",
    "\n",
    "    # Get the maximum bounding box for each table-containing page\n",
    "    max_bboxes = get_maximum_bounding_box(parsed_basic_doc, table_pages, exclude_texts)\n",
    "\n",
    "    # Open the PDF with PyMuPDF (fitz)\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    # Set the desired image resolution (in DPI)\n",
    "    dpi = 1200  # You can adjust this for higher or lower quality\n",
    "    zoom = dpi / 72  # 72 DPI is the default resolution for PDF pages\n",
    "    mat = fitz.Matrix(zoom, zoom)  # Create a transformation matrix for the resolution\n",
    "\n",
    "    # Loop through each page that contains tables and apply the crop\n",
    "    for page_idx, bbox in max_bboxes.items():\n",
    "        page = doc.load_page(page_idx)  # Load the page based on the index\n",
    "\n",
    "        # Define a rectangle for the crop (left, top, right, bottom)\n",
    "        rect = fitz.Rect(bbox[0], bbox[1], bbox[2], bbox[3])\n",
    "\n",
    "        # Set the page crop box to this rectangle\n",
    "        page.set_cropbox(rect)\n",
    "\n",
    "        # Render the cropped page as an image with the desired resolution\n",
    "        pix = page.get_pixmap(matrix=mat, alpha=False)  # alpha=False to avoid transparency\n",
    "\n",
    "        # Define the output path for the PNG\n",
    "        output_png_path = f\"{output_png_prefix}_page_{page_idx + 1}.png\"\n",
    "\n",
    "        # Save the image as PNG\n",
    "        pix.save(output_png_path)\n",
    "\n",
    "        print(f\"Cropped and saved page {page_idx + 1} as {output_png_path}\")\n",
    "\n",
    "    # Close the document\n",
    "    doc.close()\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Step 2: Extract table page data from the Excel file\n",
    "excel_file_path = 'output_pic2.xlsx'  # Path to the Excel file generated earlier\n",
    "filtered_table_matrix = extract_table_data_from_excel(excel_file_path)\n",
    "\n",
    "# Step 4: Crop the pages and save as PNG\n",
    "pdf_path = 'pic1.pdf'  # Path to your original PDF\n",
    "exclude_texts = ['Statement of Financial Position', 'The financial statements and accounting policies on pages 6']\n",
    "output_png_prefix = \"page_cropped\"\n",
    "\n",
    "crop_and_save_table_pages(pdf_path, filtered_table_matrix, test_pdf, output_png_prefix, exclude_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'nodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Example usage for Step 3:\u001b[39;00m\n\u001b[1;32m     44\u001b[0m table_pages \u001b[38;5;241m=\u001b[39m filtered_table_matrix[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()  \u001b[38;5;66;03m# Get unique pages containing tables\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m max_bboxes \u001b[38;5;241m=\u001b[39m \u001b[43mget_maximum_bounding_box\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_pdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_pages\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 16\u001b[0m, in \u001b[0;36mget_maximum_bounding_box\u001b[0;34m(parsed_basic_doc, table_pages)\u001b[0m\n\u001b[1;32m     13\u001b[0m page_bboxes \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Iterate through all the nodes in the parsed document\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[43mparsed_basic_doc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m:\n\u001b[1;32m     17\u001b[0m     page_idx \u001b[38;5;241m=\u001b[39m node[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m page_idx \u001b[38;5;129;01min\u001b[39;00m table_pages:  \u001b[38;5;66;03m# Process only pages with tables\u001b[39;00m\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;66;03m# Initialize variables to store the minimum x0, y0 and maximum x1, y1\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'nodes'"
     ]
    }
   ],
   "source": [
    "def get_maximum_bounding_box(parsed_basic_doc, table_pages):\n",
    "    \"\"\"\n",
    "    Get the maximum bounding box across all the bounding boxes for each table page.\n",
    "\n",
    "    Parameters:\n",
    "    - parsed_basic_doc: The parsed document object.\n",
    "    - table_pages: A list of page indices where tables are located.\n",
    "    \n",
    "    Returns:\n",
    "    - A dictionary with page indices as keys and max bounding boxes as values.\n",
    "    \"\"\"\n",
    "    # Initialize a dictionary to store max bounding boxes for each page\n",
    "    page_bboxes = {}\n",
    "\n",
    "    # Iterate through all the nodes in the parsed document\n",
    "    for node in parsed_basic_doc.nodes:\n",
    "        page_idx = node['page_idx']\n",
    "        \n",
    "        if page_idx in table_pages:  # Process only pages with tables\n",
    "            # Initialize variables to store the minimum x0, y0 and maximum x1, y1\n",
    "            x0_min, y0_min = float('inf'), float('inf')\n",
    "            x1_max, y1_max = float('-inf'), float('-inf')\n",
    "\n",
    "            # Extract bounding box list from node\n",
    "            if hasattr(node, 'bbox'):\n",
    "                bbox_list = node.bbox  # Assuming bbox is a list of Bbox objects\n",
    "\n",
    "                # Iterate over bbox_list (in case there are multiple Bbox objects)\n",
    "                for bbox in bbox_list:\n",
    "                    x0, y0, x1, y1 = bbox.x0, bbox.y0, bbox.x1, bbox.y1\n",
    "                    \n",
    "                    # Update the min and max values for x0, y0, x1, y1\n",
    "                    x0_min = min(x0_min, x0)\n",
    "                    y0_min = min(y0_min, y0)\n",
    "                    x1_max = max(x1_max, x1)\n",
    "                    y1_max = max(y1_max, y1)\n",
    "                \n",
    "                # Store the bounding box for the current page\n",
    "                page_bboxes[page_idx] = (x0_min, y0_min, x1_max, y1_max)\n",
    "\n",
    "    return page_bboxes\n",
    "\n",
    "# Example usage for Step 3:\n",
    "table_pages = filtered_table_matrix['page_idx'].unique()  # Get unique pages containing tables\n",
    "max_bboxes = get_maximum_bounding_box(test_pdf, table_pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page: 0\n"
     ]
    }
   ],
   "source": [
    "def iterate_table_pages(pdf_layout):\n",
    "    \"\"\"\n",
    "    Iterate over pages in the pdf_layout DataFrame that contain a table and print the page number.\n",
    "    Returns a list of page numbers with tables.\n",
    "    \"\"\"\n",
    "    # Filter for rows labeled as 'Table'\n",
    "    table_df = pdf_layout[pdf_layout['label'] == 'Table']\n",
    "    \n",
    "    # Get unique page numbers where tables are located\n",
    "    table_pages = table_df['page_idx'].unique()\n",
    "    \n",
    "    # Iterate over the pages containing tables\n",
    "    for page in table_pages:\n",
    "        print(f\"Processing page: {page}\")\n",
    "    \n",
    "    return table_pages\n",
    "\n",
    "# Call the function\n",
    "table_pages = iterate_table_pages(filtered_table_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'pages'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ww/r9bybjcn0fb_03bkvkdlt9xh0000gn/T/ipykernel_16897/2958324331.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDocumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparsed_basic_doc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_table_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparsed_basic_doc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/surya/lib/python3.10/site-packages/openparse/doc_parser.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, file, ocr)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mArgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPDF\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mocr\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mWhether\u001b[0m \u001b[0mto\u001b[0m \u001b[0muse\u001b[0m \u001b[0mOCR\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0mextraction\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mNot\u001b[0m \u001b[0mrecommended\u001b[0m \u001b[0munless\u001b[0m \u001b[0mnecessary\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minherently\u001b[0m \u001b[0mslower\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mless\u001b[0m \u001b[0maccurate\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mNote\u001b[0m \u001b[0muses\u001b[0m \u001b[0mPyMuPDF\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mOCR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \"\"\"\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         text_engine: Literal[\"pdfminer\", \"pymupdf\"] = (\n\u001b[1;32m     98\u001b[0m             \u001b[0;34m\"pdfminer\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mocr\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"pymupdf\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/surya/lib/python3.10/site-packages/openparse/pdf.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPdfReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPdfWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_pages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/surya/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'pages'"
     ]
    }
   ],
   "source": [
    "\n",
    "parser = openparse.DocumentParser()\n",
    "parsed_basic_doc=parser.parse(filtered_table_matrix)\n",
    "\n",
    "for node in parsed_basic_doc.nodes:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 5 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sequence indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m table_pages \u001b[38;5;241m=\u001b[39m filtered_table_matrix[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()  \u001b[38;5;66;03m# Assuming this contains the table page indices\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Extract only the table pages from the original PDF\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m extracted_pdf_path \u001b[38;5;241m=\u001b[39m \u001b[43mextract_table_pages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_pages\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 22\u001b[0m, in \u001b[0;36mextract_table_pages\u001b[0;34m(pdf_path, table_pages)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Extract and write only the table pages\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_idx \u001b[38;5;129;01min\u001b[39;00m table_pages:\n\u001b[0;32m---> 22\u001b[0m     page \u001b[38;5;241m=\u001b[39m \u001b[43mpdf_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpage_idx\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Extract the specific page\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     pdf_writer\u001b[38;5;241m.\u001b[39madd_page(page)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Save the new PDF containing only the table pages\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/surya/lib/python3.10/site-packages/pypdf/_page.py:2411\u001b[0m, in \u001b[0;36m_VirtualList.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m   2409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(indices\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m idx: \u001b[38;5;28mself\u001b[39m[indices[idx]])\n\u001b[1;32m   2410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m-> 2411\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence indices must be integers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2412\u001b[0m len_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   2413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2414\u001b[0m     \u001b[38;5;66;03m# support negative indexes\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence indices must be integers"
     ]
    }
   ],
   "source": [
    "import openparse\n",
    "import pypdf\n",
    "\n",
    "def extract_table_pages(pdf_path, table_pages):\n",
    "    \"\"\"\n",
    "    Extract pages that contain tables based on the table_pages indices from the original PDF.\n",
    "\n",
    "    Parameters:\n",
    "    - pdf_path: Path to the original PDF file.\n",
    "    - table_pages: List of page indices where tables are located.\n",
    "    \n",
    "    Returns:\n",
    "    - Path to the temporary extracted PDF containing only the table pages.\n",
    "    \"\"\"\n",
    "    # Open the original PDF file\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = pypdf.PdfReader(file)\n",
    "        pdf_writer = pypdf.PdfWriter()\n",
    "\n",
    "        # Extract and write only the table pages\n",
    "        for page_idx in table_pages:\n",
    "            page = pdf_reader.pages[page_idx]  # Extract the specific page\n",
    "            pdf_writer.add_page(page)\n",
    "        \n",
    "        # Save the new PDF containing only the table pages\n",
    "        output_pdf_path = \"table_pages_extracted.pdf\"\n",
    "        with open(output_pdf_path, 'wb') as output_pdf:\n",
    "            pdf_writer.write(output_pdf)\n",
    "\n",
    "    return output_pdf_path\n",
    "\n",
    "# Example usage:\n",
    "pdf_path = \"pic2.pdf\"\n",
    "table_pages = filtered_table_matrix['page_idx'].unique()  # Assuming this contains the table page indices\n",
    "\n",
    "# Extract only the table pages from the original PDF\n",
    "extracted_pdf_path = extract_table_pages(pdf_path, table_pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "insert_page() got an unexpected keyword argument 'from_page'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m output_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextracted_table_pages\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Folder where individual PDFs will be saved\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Extract and save each page containing tables as separate PDFs\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m saved_pdfs \u001b[38;5;241m=\u001b[39m \u001b[43mextract_and_save_table_pages_separately\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_pages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted PDFs saved at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msaved_pdfs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 32\u001b[0m, in \u001b[0;36mextract_and_save_table_pages_separately\u001b[0;34m(pdf_path, table_pages, output_folder)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Create a new PDF with just this single page\u001b[39;00m\n\u001b[1;32m     31\u001b[0m single_page_pdf \u001b[38;5;241m=\u001b[39m fitz\u001b[38;5;241m.\u001b[39mopen()\n\u001b[0;32m---> 32\u001b[0m \u001b[43msingle_page_pdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_page\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Define the path for the output PDF\u001b[39;00m\n\u001b[1;32m     35\u001b[0m output_pdf_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable_page_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_idx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: insert_page() got an unexpected keyword argument 'from_page'"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "\n",
    "def extract_and_save_table_pages_separately(pdf_path, table_pages, output_folder):\n",
    "    \"\"\"\n",
    "    Extract each page containing a table and save it as a separate PDF.\n",
    "\n",
    "    Parameters:\n",
    "    - pdf_path: Path to the original PDF file.\n",
    "    - table_pages: List of page indices where tables are located (ensure it's integers).\n",
    "    - output_folder: Folder to save the individual page PDFs.\n",
    "    \n",
    "    Returns:\n",
    "    - A list of paths to the saved individual PDFs.\n",
    "    \"\"\"\n",
    "    # Ensure the output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Open the original PDF\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    # List to store the paths of saved PDFs\n",
    "    saved_pdfs = []\n",
    "\n",
    "    # Loop through the provided page indices and extract the corresponding pages\n",
    "    for page_idx in table_pages:\n",
    "        page = doc.load_page(int(page_idx))  # Load the page by index\n",
    "\n",
    "        # Create a new PDF with just this single page\n",
    "        single_page_pdf = fitz.open()\n",
    "        single_page_pdf.insert_page(-1, from_page=page)\n",
    "\n",
    "        # Define the path for the output PDF\n",
    "        output_pdf_path = os.path.join(output_folder, f\"table_page_{page_idx + 1}.pdf\")\n",
    "        single_page_pdf.save(output_pdf_path)\n",
    "        single_page_pdf.close()\n",
    "\n",
    "        # Append the path to the list\n",
    "        saved_pdfs.append(output_pdf_path)\n",
    "\n",
    "    doc.close()\n",
    "\n",
    "    return saved_pdfs\n",
    "\n",
    "# Example usage:\n",
    "pdf_path = \"pic2.pdf\"\n",
    "table_pages = filtered_table_matrix['page_idx'].unique().tolist()  # Convert to list of integers if necessary\n",
    "output_folder = \"extracted_table_pages\"  # Folder where individual PDFs will be saved\n",
    "\n",
    "# Extract and save each page containing tables as separate PDFs\n",
    "saved_pdfs = extract_and_save_table_pages_separately(pdf_path, table_pages, output_folder)\n",
    "\n",
    "print(f\"Extracted PDFs saved at: {saved_pdfs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted PDFs saved at: ['extracted_table_pages/table_page_1.pdf']\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "\n",
    "def extract_and_save_table_pages_separately(pdf_path, table_pages, output_folder):\n",
    "    \"\"\"\n",
    "    Extract each page containing a table and save it as a separate PDF.\n",
    "\n",
    "    Parameters:\n",
    "    - pdf_path: Path to the original PDF file.\n",
    "    - table_pages: List of page indices where tables are located (ensure it's integers).\n",
    "    - output_folder: Folder to save the individual page PDFs.\n",
    "    \n",
    "    Returns:\n",
    "    - A list of paths to the saved individual PDFs.\n",
    "    \"\"\"\n",
    "    # Ensure the output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Open the original PDF\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    # List to store the paths of saved PDFs\n",
    "    saved_pdfs = []\n",
    "\n",
    "    # Loop through the provided page indices and extract the corresponding pages\n",
    "    for page_idx in table_pages:\n",
    "        page = doc.load_page(int(page_idx))  # Load the page by index\n",
    "\n",
    "        # Create a new PDF with just this single page\n",
    "        single_page_pdf = fitz.open()\n",
    "        single_page_pdf.new_page(width=page.rect.width, height=page.rect.height)\n",
    "        single_page_pdf[-1].show_pdf_page(page.rect, doc, page_idx)  # Copy the page content\n",
    "        \n",
    "        # Define the path for the output PDF\n",
    "        output_pdf_path = os.path.join(output_folder, f\"table_page_{page_idx + 1}.pdf\")\n",
    "        single_page_pdf.save(output_pdf_path)\n",
    "        single_page_pdf.close()\n",
    "\n",
    "        # Append the path to the list\n",
    "        saved_pdfs.append(output_pdf_path)\n",
    "\n",
    "    doc.close()\n",
    "\n",
    "    return saved_pdfs\n",
    "\n",
    "# Example usage:\n",
    "pdf_path = \"pic2.pdf\"\n",
    "table_pages = filtered_table_matrix['page_idx'].unique().tolist()  # Convert to list of integers if necessary\n",
    "output_folder = \"extracted_table_pages\"  # Folder where individual PDFs will be saved\n",
    "\n",
    "# Extract and save each page containing tables as separate PDFs\n",
    "saved_pdfs = extract_and_save_table_pages_separately(pdf_path, table_pages, output_folder)\n",
    "\n",
    "print(f\"Extracted PDFs saved at: {saved_pdfs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PyPDF2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPyPDF2\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'PyPDF2'"
     ]
    }
   ],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyPdf2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenparse\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyPdf2\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_table_pages\u001b[39m(pdf_path, table_pages):\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    Extract pages that contain tables based on the table_pages indices from the original PDF.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    - Path to the temporary extracted PDF containing only the table pages.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyPdf2'"
     ]
    }
   ],
   "source": [
    "import openparse\n",
    "import pyPdf2\n",
    "\n",
    "def extract_table_pages(pdf_path, table_pages):\n",
    "    \"\"\"\n",
    "    Extract pages that contain tables based on the table_pages indices from the original PDF.\n",
    "\n",
    "    Parameters:\n",
    "    - pdf_path: Path to the original PDF file.\n",
    "    - table_pages: List of page indices where tables are located.\n",
    "    \n",
    "    Returns:\n",
    "    - Path to the temporary extracted PDF containing only the table pages.\n",
    "    \"\"\"\n",
    "    # Open the original PDF file\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        pdf_writer = PyPDF2.PdfWriter()\n",
    "\n",
    "        # Extract and write only the table pages\n",
    "        for page_idx in table_pages:\n",
    "            page = pdf_reader.pages[page_idx]  # Extract the specific page\n",
    "            pdf_writer.add_page(page)\n",
    "        \n",
    "        # Save the new PDF containing only the table pages\n",
    "        output_pdf_path = \"table_pages_extracted.pdf\"\n",
    "        with open(output_pdf_path, 'wb') as output_pdf:\n",
    "            pdf_writer.write(output_pdf)\n",
    "\n",
    "    return output_pdf_path\n",
    "\n",
    "# Example usage:\n",
    "pdf_path = \"pic2.pdf\"\n",
    "table_pages = filtered_table_matrix['page_idx'].unique()  # Assuming this contains the table page indices\n",
    "\n",
    "# Extract only the table pages from the original PDF\n",
    "extracted_pdf_path = extract_table_pages(pdf_path, table_pages)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surya",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
